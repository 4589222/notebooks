{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algumas definições\n",
    "\n",
    "Em algumas direções, uma transformação linear se comporta como multiplicação por escalar. Estas direções e seus respectivos fatores multiplicativos são propriedade da transformação (isto é, da matriz) e são chamados de [autovetores e autovalores](https://pt.wikipedia.org/wiki/Autovalores_e_autovetores), respectivamente.\n",
    "\n",
    "Ou seja, se $A$ for uma matriz quadrada, um vetor não-nulo $v$ é autovetor de $A$ com autovalor $\\sigma$ se\n",
    "\n",
    "$$A v = \\sigma v$$\n",
    "\n",
    "Se rearranjarmos a equação, podemos observar que $v$ é solução do sistema de equações homogêneo\n",
    "\n",
    "$$(A - \\sigma I) v = 0$$\n",
    "\n",
    "onde $I$ é a matriz identidade de mesma dimensão de $A$.\n",
    "Soluções não-nulas só vão existir se $A - \\sigma I$ representar uma transformação singular, ou seja, se $p(\\sigma) = \\det(A - \\sigma I) = 0$.\n",
    "O polinômio $p(\\sigma)$ chamado de [polinômio característico](https://pt.wikipedia.org/wiki/Polin%C3%B4mio_caracter%C3%ADstico) de $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os métodos automáticos: `numpy.linalg.eig*`\n",
    "\n",
    "No futuro pretendo escrever sobre obtenção de raízes de polinômios mas, na prática, obter autovalores dessa maneira é ineficiente.\n",
    "O pacote NumPy de álgebra linear para Python é capaz de encontrar autovalores e autovetores de matrizes de maneira muito mais eficiente.\n",
    "\n",
    "Primeiro, vamos definir uma matriz e, depois, calcular *apenas seus autovalores* com `numpy.linalg.eigvals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1., 0.], [0., 4.]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.linalg.eigvals(A)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a matriz acima é diagonal, seus autovalores correspondem às entradas da diagonal.\n",
    "Vamos calcular agora para uma matriz não-diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1., 2.], [3., 4.]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37228132,  5.37228132])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.linalg.eigvals(B)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para [matrizes **h**ermitianas](https://pt.wikipedia.org/wiki/Matriz_transposta_conjugada) (ou [simétricas](https://pt.wikipedia.org/wiki/Matriz_sim%C3%A9trica)) existe uma função especializada mais eficiente, `numpy.linalg.eigvalsh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.array([[2., 3.], [3., 4.]])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16227766,  6.16227766])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferença entre as duas funções acima está (i) nos valores que acessam (a `numpy.linalg.eigvalsh` só precisa usar metade dos elementos da matriz, já que ela é simétrica) e, principalmente, (ii) na eficiência.\n",
    "Abaixo comparamos os tempos de execução para ambas as funções para uma matriz simétrica um pouco maior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 2., 3.],\n",
       "       [0., 0., 3., 4.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.block([[np.eye(2), np.zeros([2, 2])],\n",
    "              [np.zeros([2, 2]), S]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.22 µs ± 373 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.eigvalsh(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.3 µs ± 1.43 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.eigvals(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dá logo para perceber que, quando a matriz for simétrica ou **h**ermitiana, vale a pena usar a função especializada: o tempo de execução pode chegar a ser duas vezes menor.\n",
    "Outra diferença é que, como matrizes simétricas ou **h**ermitianas possuem sempre autovalores reais, funções especializadas como `numpy.linalg.eigvalsh` irão sempre garantir que o resultado seja não-complexo.\n",
    "(Se tivéssemos usado `numpy.linalg.eigvals` e tivéssemos certeza de que nossos autovalores são todos reais, poderíamos ter tomado apenas a parte real do vetor fazendo `sigma.real`.)\n",
    "\n",
    "Mas e os autovetores?\n",
    "O conjunto de vetores com seus autovalores correspondentes pode ser obtido com a função `numpy.linalg.eig` (ou `numpy.linalg.eigh`, se a matriz for simétrica ou **h**ermitiana):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se é diagonal, é simétrica\n",
    "sigma, U = np.linalg.eigh(A)\n",
    "display(sigma, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas funções `numpy.linalg.eig` e `numpy.linalg.eigh` retornam dois objetos, um *array* unidimensional e um bidimensional.\n",
    "O primeiro, um vetor (chamado aqui de $\\sigma$), contém os autovalores.\n",
    "O segundo, uma matriz (aqui chamado de $U$), contém os respectivos autovetores, *um autovetor por coluna*, na posição correspondente do seu autovalor em $\\sigma$.\n",
    "Vale também observar que os autovetores são retornados normalizados (normas euclidianas iguais a um).\n",
    "\n",
    "Como dito, a ordem deles \"bate\", de forma que o autovalor $\\sigma_0$ (`sigma[0]`) está associado ao autovetor apresentado na zeroésima coluna de $U$ ($U_{:0}$ ou `U[:, 0]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Observe que, quando extraímos a primeira coluna de $U$, obtemos um *array* unidimensional, o que é típico do NumPy.)\n",
    "\n",
    "Agora fica fácil verificar que a condição de autovalor/autovetor é satisfeita para $\\sigma_0$ e $U_{:0}$.\n",
    "Simplesmente realizamos ambas multiplicações $A v$ e $\\sigma v$ da condição e verificamos se ambas resultam iguais. A verificação disso fica fácil com `numpy.allclose`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A @ U[:, 0], sigma[0] * U[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos resultados são portanto o mesmo, como devem ser.\n",
    "É claro que o mesmo ocorre com o segundo par $\\sigma_1$ e $U_{:1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A @ U[:, 1], sigma[1] * U[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma propriedade muito útil das matrizes simétricas (ou **h**ermitianas) é que seus autovetores são em geral ortogonais (quando não degenerados). Vamos verificar isso abaixo para a matriz $S$, para a qual havíamos calculado apenas autovalores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16227766,  6.16227766])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.81124219,  0.58471028],\n",
       "       [ 0.58471028,  0.81124219]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma, U = np.linalg.eigh(S)\n",
    "display(sigma, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:, 0] @ U[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto interno entre autovetores associados a autovalores distintos é zero, o que caracteriza ortogonalidade.\n",
    "Já que os autovetores também estão normalizados, isso quer dizer que $U$ é unitária, ou seja,\n",
    "\n",
    "$$U^T U = I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(U.T @ U, np.eye(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, em uma comparação análoga à anterior, observe o efeito no tempo de execução ao se utilizar a função `numpy.linalg.eigh` ao invés de `numpy.linalg.eig` para matrizes simétricas ou **h**ermitianas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 µs ± 904 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sigma, U = np.linalg.eigh(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 µs ± 2.86 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sigma, U = np.linalg.eig(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenando autovalores e autovetores\n",
    "\n",
    "Os autovalores retornados de `numpy.linalg.eigh` ou `numpy.linalg.eigvalsh` são sempre retornados em ordem ascendente e repetidos de acordo com suas multiplicidades.\n",
    "No entanto, as funções `numpy.linalg.eig` e `numpy.linalg.eigvals` não garantem ordenamento dos autovalores, mas existe uma maneira de ordená-los e corrigir a ordem dos autovetores de acordo usando `numpy.argsort`.\n",
    "\n",
    "Vamos gerar uma matriz aleatória $4 \\times 4$ usando `numpy.random.rand`, calcular seus autovalores e autovetores, e reordená-los em ordem ascendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.91515211+0.j        ,  0.38355489+0.20195601j,\n",
       "        0.38355489-0.20195601j, -0.2697303 +0.j        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.2697303 +0.j        ,  0.38355489-0.20195601j,\n",
       "        0.38355489+0.20195601j,  1.91515211+0.j        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.random.rand(4, 4)\n",
    "sigma, U = np.linalg.eig(A)\n",
    "display(sigma)\n",
    "\n",
    "indices = np.argsort(sigma)\n",
    "sigma = sigma[indices]\n",
    "U = U[:, indices]\n",
    "display(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonalização\n",
    "\n",
    "Uma matriz quadrada é [diagonalizável](https://pt.wikipedia.org/wiki/Matriz_diagonaliz%C3%A1vel) se ela é similar à uma matriz diagonal. Ou seja, $A$ é diagonalizável se existe uma matriz invertível $V$ tal que\n",
    "\n",
    "$$\\Sigma = V^{-1} A V$$\n",
    "\n",
    "seja diagonal.\n",
    "Um resultado interessante da álgebra linear é que uma matriz quadrada $A$ de tamanho $n$ é diagonalizável se e somente se ela possui $n$ autovetores linearmente independentes. As colunas de $V$ terão então os autovetores de $A$ e $\\Sigma$ terá os autovalores na diagonal.\n",
    "\n",
    "Portanto, se tivermos todos os autovalores e autovetores de uma matriz, toda a informação para sabermos se ela é diagonalizável e toda a informação para a diagonalização já estará disponível.\n",
    "Podemos construir a matriz diagonal a partir dos autovalores com `numpy.diag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2697303 +0.j        ,  0.        +0.j        ,\n",
       "         0.        +0.j        ,  0.        +0.j        ],\n",
       "       [ 0.        +0.j        ,  0.38355489-0.20195601j,\n",
       "         0.        +0.j        ,  0.        +0.j        ],\n",
       "       [ 0.        +0.j        ,  0.        +0.j        ,\n",
       "         0.38355489+0.20195601j,  0.        +0.j        ],\n",
       "       [ 0.        +0.j        ,  0.        +0.j        ,\n",
       "         0.        +0.j        ,  1.91515211+0.j        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, se os autovetores forem ortonormais, podemos nos valer do fato de que $U^{-1} = U^T$ (ou seja, como visto acima, $U$ será unitária):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.linalg.inv(U), U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54099418+0.17689684j, -0.1086356 +0.03839203j,\n",
       "        -0.22377567-0.09720118j, -0.01058118-0.07770512j],\n",
       "       [-0.1086356 +0.03839203j,  0.08516411-0.24702832j,\n",
       "         0.31191995-0.06718322j,  0.13681642+0.21232781j],\n",
       "       [-0.22377567-0.09720118j,  0.31191995-0.06718322j,\n",
       "         0.13608851+0.03815938j,  0.19298666-0.34693977j],\n",
       "       [-0.01058118-0.07770512j,  0.13681642+0.21232781j,\n",
       "         0.19298666-0.34693977j,  0.31502865-0.03682457j]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.T @ np.diag(sigma) @ U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos usar este truque para construírmos matrizes com autovalores e autovetores desejados, fazendo apenas a operação inversa ($C = V \\Sigma V^{-1}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  0],\n",
       "       [ 1, -1,  0],\n",
       "       [ 1,  1,  1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([[1, 1, 0], [1, -1, 0], [1, 1, 1]])\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.array([3, 1, 2])\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 0.],\n",
       "       [1., 2., 0.],\n",
       "       [0., 1., 2.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = V @ np.diag(sigma) @ np.linalg.inv(V)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcularmos os autovalores e autovetores de `C`, veremos que obtivemos êxito em construir uma matriz com exatamente os autovalores e autovetores desejados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.57735027,  0.57735027],\n",
       "       [ 0.        ,  0.57735027, -0.57735027],\n",
       "       [ 1.        ,  0.57735027,  0.57735027]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma, V = np.linalg.eig(C)\n",
    "display(sigma, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe acima que (i) a ordem dos autovalores não é necessáriamente a que usamos (embora possamos reordená-los como visto anteriormente) e que (ii) os autovetores diferem por terem sido retornados normalizados (embora preservem colinearidade com os que havíamos escolhido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potenciação de matrizes por diagonalização\n",
    "\n",
    "Seja $A$ uma matriz quadrada.\n",
    "Calcular as potências de $A$ por multiplicação matricial\n",
    "\n",
    "$$A^k = \\overbrace{A A \\cdots A}^{k \\text{ multiplicações}}$$\n",
    "\n",
    "é ineficiente.\n",
    "[Já vimos em outro texto](http://schneiderfelipe.xyz/matrizes-e-vetores/#Potencia%C3%A7%C3%A3o-matricial), por exemplo, que a função `numpy.linalg.matrix_power` não faz todas as multiplicações intermediárias e é mais rápida. Mas lá não havíamos dito como isso funciona.\n",
    "Aqui vamos ver uma maneira eficiente de potenciar matrizes, semelhante à implementada em `numpy.linalg.matrix_power`.\n",
    "\n",
    "Se tivermos diagonalizado a matriz $A = V \\Sigma V^{-1}$, podemos fazer\n",
    "\n",
    "$$A^k = \\left(V \\Sigma V^{-1}\\right)^k = \\overbrace{V \\Sigma V^{-1} V \\Sigma V^{-1} \\cdots V \\Sigma V^{-1}}^{k \\text{ multiplicações}}\n",
    "= V \\Sigma^k V^{-1}$$\n",
    "\n",
    "Ou seja, $V$ também diagonaliza a $k$-ésima potência de $A$, cujos autovalores são a $k$-ésima potência dos de $A$.\n",
    "\n",
    "Vamos gerar uma matriz aleatória $4 \\times 4$ usando `numpy.random.rand`, calcular $A^{50}$ das duas maneiras e medir o tempo de execução.\n",
    "Depois vamos comparar com o tempo de cálculo de `numpy.linalg.matrix_power`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63793558, 0.73715957, 0.89984734, 0.70444143],\n",
       "       [0.94404201, 0.22125809, 0.60741571, 0.56164526],\n",
       "       [0.35590991, 0.71898612, 0.60455103, 0.05662982],\n",
       "       [0.64455821, 0.03599551, 0.0969152 , 0.52545749]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(4, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.14018072,  0.44379691, -0.36299497, -0.23178048])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.66012609,  0.00078128, -0.33430846, -0.09979794],\n",
       "       [-0.54561856, -0.08857098,  0.77481098, -0.73386412],\n",
       "       [-0.41955082,  0.6578778 , -0.46813645,  0.67106746],\n",
       "       [-0.30085054, -0.74789797,  0.26220997,  0.03394541]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma, V = np.linalg.eig(A)\n",
    "display(sigma, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Observe que, para a matriz obtida, tanto os autovalores quanto os autovetores possuem entradas complexas.)\n",
    "\n",
    "O código abaixo se vale do fato de que a potenciação de uma matriz diagonal é equivalente à potenciação individual das entradas da diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.2 µs ± 5.43 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "V @ np.diag(sigma**50) @ np.linalg.inv(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.5 µs ± 1.26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A @ A @ A @ A @ A @ A @ A @ A @ A @ A \\\n",
    "@ A @ A @ A @ A @ A @ A @ A @ A @ A @ A \\\n",
    "@ A @ A @ A @ A @ A @ A @ A @ A @ A @ A \\\n",
    "@ A @ A @ A @ A @ A @ A @ A @ A @ A @ A \\\n",
    "@ A @ A @ A @ A @ A @ A @ A @ A @ A @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica claro que diagonalização computa potenciação muito mais rapidamente. Porém vale comentar que não estamos levando em consideração o tempo necessário para se computar $V$ e $\\Sigma$. Se levarmos isso em conta, o método não é assim tão competitivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 µs ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sigma, V = np.linalg.eig(A)\n",
    "V @ np.diag(sigma**50) @ np.linalg.inv(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, nenhum deles chega a ganhar da função `numpy.linalg.matrix_power`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 µs ± 255 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.matrix_power(A, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talvez eu escreva um texto no futuro sobre os motivos pelos quais funções como a `numpy.linalg.matrix_power` são tão rápidas.\n",
    "Mas, por hora, completamos essa série sobre álgebra linear e Python.\n",
    "O próximo texto será o primeiro de uma série sobre gráficos e visualização de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
